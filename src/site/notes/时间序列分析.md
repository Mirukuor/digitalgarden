---
{"dg-publish":true,"permalink":"/时间序列分析/","dgPassFrontmatter":true,"noteIcon":"2"}
---

#课程 #数学 
教材：Introduction to Time Series and Forecasting（Springer 2016 第三版）
	Time Series: Theory and Methods, 2nd Edition（Springer 1991 第二版）
软件：ITSM2000（平滑随机项）——ITSMr（R语言）

# Chapter 1 什么是时间序列
## 1.1 定义
**定义1 随机过程**. 一列随机变量$\{X_1, X_2, ……X_n, ……\}$，称为(离散)时间 n 的随机过程。
假定需要分析的模型*复杂、独特、不可复制*，所以只能收集一次数据。

**定义2 时间序列模型**. 一个随机过程模型的一次实现，就是取$X_1, X_2, ……$在一个时间段的一次观测值。
显然一次实现不能获得随机过程模型的完整信息。但是我们希望能尽量获取部分信息。这也就是时间序列分析的意义。实际应用中，我们只期望能得到随机过程的一阶矩相关信息也就是期望 $E_X$，以及二阶矩相关信息，也就是 $E[X_m,X_n]$，或者(在一阶矩已知情况下)等价的(协)方差$Cov(X_m,X_n)$。
![意大利月度红酒销量.png](/img/user/%E6%84%8F%E5%A4%A7%E5%88%A9%E6%9C%88%E5%BA%A6%E7%BA%A2%E9%85%92%E9%94%80%E9%87%8F.png)

可能包含*趋势、季节性波动*

## 1.2 时间序列的分解
我们的时间序列分析的第一步，就是把趋势项($m_t$)和季节项($st$)剥离出来，然后研究剩下的随机项，也就是把 X写成$$X_t=m_t+s_t+H$$其中 $m_t$ 和 $s_t$ 都是确定的函数。这叫做**时间序列的分解**
### 1.2.1 没有季节项时，如何分离趋势项
#### 方法A. 有限移动平均滤波器（finite moving average filter）平滑数据
$$\hat{m}_t=\frac{1}{2q+1}\sum_{j=-q}^{q}X_{t-j}$$
其中正整数q称为**滤波器的阶**

例如： $\hat{m}_n=\frac{m_{n-1}+m_n+m_{n+1}}{3}+\frac{Y_{n-1}+Y_n+Y_{n+1}}{3}$ 中随机项求平均后相互抵消约为零，而趋势项平均不掉。
如果已知这个趋势是线性的，则取大一些的q能更有效地“过滤”噪声。但是，如果趋势不是线性，太大的q可能会扭曲真正的趋势
#### 方法B. 指数平滑
选取一个 $\alpha\in[0,1]$ ，然后从t=1出发，将$1-\alpha$为前项权重，逐项计算$\hat{m}_t$
$$\hat{m}_t=\sum_{j=0}^{t-2}\alpha(1-\alpha)^jX_{t-j}+(1-\alpha)^{t-1}X_1$$
#### 方法C. 傅里叶变换
如果我们有一个定义在$[0,n]$上面的连续函数，我们可以对它做傅里叶展开。用一个**低通滤波器**截掉高频部分保留低频部分。
#### 方法D. 多项式拟合
如果我们有理由相信趋势是多项式的 $m_t = a_0 + a_1t + a_2t^2+……$ 
$\iff$ 最小二乘法求拟合误差 $\sum_{t=1}^n(X_t-m_t)^2$ 的极值问题（绝对值在零点不可导）
$\iff$ $\frac{\partial}{\partial a_j}[\sum_{t=1}^n(X_t-m_t)^2]=0$ 
#### 方法F. 高阶差分法
定义**滞后算子** $BX_i=X_{i-1}$
定义**差分算子**$$\nabla X_t=X_{t}-X_{t-1}$$
若 $m_t$ 是k次多项式，则经过k+1阶差分 $\nabla^{k+1}X_t$ 则可完全消除趋势项（包括常数）
### 1.2.2 同时具有趋势项和季节项时，怎么分离他们
根据数据性质明确周期
#### 方法A. 估计趋势项和季节项
跨季节移动平均滤波，取 $q=(d-1)/2$ 消除季节项
去除趋势项后取不同周期同时间的平均，再减去其平均值（要求季节的和为0），得到季节项的近似
#### 方法B. 利用差分消除趋势项和季节项
定义d-滞后算子：$$\nabla_d X_t=X_t-X_{t-d}$$
再对$\{\nabla_d X_t\}$ 用差分方法消除趋势项
## 1.3 时间序列的统计特征
一组随机向量$Y=(y_1, …, y_t,…)^T$，$y_t$ 代表t时刻的随机变量，则
- 均值 $\mu_t=E(y_t)$ 
- 方差 $\sigma^2=E(y_t-\mu_t)^2$ 
- 自协方差 $\gamma(t,k)=Cov(y_t,y_k)=E[(y_t-\mu_t)(y_k-\mu_k)]$ 
	- 对称性 $\gamma(t,k)=\gamma(k,t)$ 
	- 非负定性 自协方差矩阵 $\Gamma_m=[\begin{matrix}\gamma(1,1)&\gamma(1,2)&…&\gamma(1,m)\\ \vdots&\vdots&\ddots&\vdots\\ \gamma(m,1)&\gamma(m,2)&…&\gamma(m,m)\end{matrix}]$ 对称非负定
	 ==*证明*==：任意向量x，二次项=$D(x^TY)\geqslant 0$ 
- 自相关系数 $\rho(t,k)=\frac{\gamma(t,k)}{\sigma_t \times \sigma_k}$ 
	- 规范性 $\rho(t,t)=1$ 且$|\rho(t,k)|\leqslant 1$ 
	- 对称性 $\rho(t,k)=\rho(k,t)$ 
	- 非负定性
# Chapter 2 平稳时间序列
## 2.1 平稳模型和自相关函数
每刻只能得到该随机变量的单个观测值，无法估计分布特征，所以施加一个条件，使由实现值的单一集合的统计量充分接近其总体平均
**定义3 严格平稳过程**. 任意联合分布相同，即 $\forall n,h \in \mathbb{Z_+}, (X_1,…X_n) \overset{d}{=} (X_{1+h},…, X_{n+h})$ 。
**定义4 (弱)平稳过程**. 认为序列的统计性质主要由低阶矩决定，所以保证前两阶平稳。
	1. 均值恒定
	2. 方差有界
	3. 自相关系数是时间间隔的函数
	对于随机过程$\{X_t\}, \forall t, E(X_t^2)<\infty$ ，定义其均值函数和协方差函数：$$\begin{matrix} \mu x(t)=E(X_t) \\ \gamma x(r,s)=Cov(X_r,X_s)=E[(X_r-\mu x(r))(X_s-\mu x(s))] \end{matrix}$$
满足：
1. $\mu x(t)$ 与t无关
2. $\gamma x(t+h,t)$ 与t无关
定义**自协方差函数（ACVF）**$$\gamma(h)=Cov(X_{t+h},X_t)$$
只与**时滞h**有关，而与时间起始位置t无关，满足性质：
1. $\gamma(0) \geqslant 0$
2. $|\gamma(h)|\leqslant \gamma(0)$ 
3. $\gamma(h)=\gamma(-h)$
4. 非负定性，即 $$\forall n \in \mathbb{Z}_+, \vec{a}\in \mathbb{R}^n, \sum_{i,j=1}^{n}a_i \gamma(i-j)a_j \geqslant 0$$
定义**自相关（系数）函数（ACF）**$$\rho(h)=\frac{\gamma(h)}{\gamma(0)}$$
**定理1.** 一列实数对称，且非负定 $\iff$ 他是某平稳过程的自协方差函数
至此便可以用所有时间点上各样本的集合来估计一阶矩和二阶矩：$$\begin{matrix} \hat{\mu}=\bar{x}=\frac{1}{T}\sum_{t=1}^{T}x_t \\ \hat{\sigma}^2=\frac{1}{T-1}\sum_{t=1}^{T}(x_t-\bar{x})^2 \\ \hat{\gamma_h}=\hat{\gamma_{-h}}=\frac{1}{T-h}\sum_{t=1}^{T-h}(x_t-\bar{x})(x_{t+h}-\bar{x}) \\ \hat{\rho_h}=\hat{\rho_{-h}}=\frac{\hat{\gamma_h}}{\hat{\gamma_0}} \end{matrix}$$
## 2.2 白噪声过程
**定义5 白噪声**. $\{\varepsilon_t\}$ 满足零均值、同方差、非自相关。特别的，服从正态分布为**高斯白噪声**，相互独立为**iid白噪声** $\{Z_t\} \sim IID(0,\sigma^2)$ 。
**定义6 移动平均—MA(q)过程**. $X_t=Z_t+\theta_1Z_{t-1}+...+\theta_qZ_{q-1}$ 当前值是由过去的误差线性组合的
q=1时 $$\gamma x(h)=\begin{cases}\sigma^2(1+\theta^2),&h=0 \\ \sigma^2\theta,&h=\pm 1 \\ 0,&|h|\geqslant1 \end{cases}$$ 
**定理2**. 如果平稳过程 $\{X_t\}$ 均值为0且q-相关，则它可以表示为 $MA(q)$ 过程。（类似解析函数的泰勒展开）
	*==证明==*：$\int X_n^2dp<\infty \iff X_n in L^2$ 构成希尔伯特空间，验证正交、线性组合
推广为$MA(\infty)$过程：$X_t=\psi(B)Z_t, \psi(B)=\sum_{j=0}^{\infty}\psi_jB^j$ ==现在不受未来影响==
推广为线性过程： $X_t=\psi(B)Z_t, \psi(B)=\sum_{j=-\infty}^{\infty}\psi_jB^j$  ==现在受未来影响==
$$\gamma_X(h)=\sum_{j=-\infty}^\infty\psi_j\psi_{j+h}\sigma^2.$$
**定理3.** 令$\{Y_i\}$为平稳过程，满足均值为0且自协方差函数为$\gamma_Y$。如果$\sum_{-\infty}^{\infty}|\psi_j|< -\infty$且$X_t=\sum_{j=-\infty}^\infty\psi_jY_{t-j}=\psi(B)Y_t$ ，则$\{X_t\}$也是满足均值为0的平稳过程，且其自协方差函数（ACVF）为$$\gamma_X(h)=\sum_{j,k=-\infty}^{\infty}\psi_j\psi_k\gamma_Y(h+k-j).$$
	==*证明*==：代入求$E[X_{t+h}X_t]$ 【注：求期望（在概率空间求积分）和无穷求和交换】
## 2.3 时间序列的统计估计
### 估计均值
$$E(\bar{X}_n)=\mu=n^{-1}(x_1+...+x_n)$$
**定理4**. $\{X_n\}$为平稳过程，均值为$\mu$，自协方差$\gamma(h)$则：如果$\gamma(n)\to 0$，则$Var(\bar{X}_n)\to 0$
### 估计自协方差与自相关
$$\hat{\gamma}(h)=n^{-1}\sum_{t=1}^{n-|h|}(X_{t+|h|}-\bar{X}_n)(X_{t}-\bar{X}_n),\hat{\rho}(h)=\frac{\hat{\gamma}(h)}{\hat{\gamma}(0)},(n\geqslant 50, h\leqslant n/4)$$
把$n^{-1}$替换为$(n-h)^{-1}$仍然有偏，且破坏了自协方差矩阵的非负定
	*==证明==*：$\vec{a}'\hat{\Gamma}_k\vec{a}=n^{-1}(\vec{a}T)(\vec{a}T)'\geqslant 0$ 
**定理5**. 平稳过程$\{X_n\}$满足$X_t=\mu+\sum_{j=-\infty}^{\infty}\psi_jZ_{t-j}, Z_t\sim IID(0,\sigma^2)$ 且$\sum_{j=-\infty}^{\infty}|\psi_j|<\infty, EZ_t^4<\infty$ ，那么随着n增大，随机向量$(\hat{\rho}(1),...\hat{\rho}(h))$分布趋于渐进正态$N(\vec{\rho},n^{-1}W)$ 

# Chapter 3 时间序列的估计
## 3.1 是不是IID
### A. 样本自相关函数
n项样本自相关函数$\hat{\rho}(h)$的分布大约是各自独立的$N(0,n^{-1})$，那么==95%的$\hat{\rho}(h)$应该落在$\pm1.96/\sqrt{n}$==.
例如$\hat{\rho}(1)\sim\hat{\rho}(40)$ 中两个点在边界外，或者一个点超过边界很远，说明$IID(0,\sigma^2)$假设被推翻
### B. 混成检验
$\chi^2$分布：h个$N(0,1)$独立正态分布随机变量的平方和
$$Q=n\sum_{j=1}^h\hat{\rho}^2(j)\sim \chi^2$$
Ljung-Box检验更接近$\chi^2$分布：
$$Q_{LB}=n(n+2)\sum_{j=1}^h\frac{\hat{\rho}^2(j)}{n-j}\sim \chi^2(h)$$
### C. 转折点检验
转折点T：$y_{i-1}<y_i 且 y_i>y_{i+1}$ 或 $y_{i-1}>y_i 且 y_i<y_{i+1}$，每个i是转折点概率为2/3$$E(T)=\frac23(n-2)\ \ \ Var(T)=\frac{16n-29}{90}$$
n很大时，T近似于正态分布，就可以用$|T-\mu_T|/\sigma_T>\Phi_{1-\alpha/2}$的假设推翻显著性水平α(一般取0.05，φ=1.96）的iid假设
### D. 变号检验
增长点S：$y_i>y_{i-1}$ （2-周期性最好不用变号检验）$$E(S)=\frac12(n-1)\ \ \ Var(S)=\frac{n+1}{12}$$
### E. 秩检验
秩P：$i<j,y_i<y_j的(i,j)对的个数$ $$E(P)=\frac14(n-1)\ \ \ Var(S)=\frac{n(n-1)(2n+5)}{72}$$
### F. 拟合自回归模型
### G. 检验正态性
高斯过程：$Y_{t_1},...Y_{t_k}$ 联合分布都是k-维正态分布
随机变量$\{Y_i\}$与iid N(0,1)$\{X_i\}$ 从小到大排序。令$E[X_{(j)}]=m_j$，假设$\{Y_i\}\sim N(\mu,\sigma^2)$，则有：$$E[Y_{(j)}]=\mu+\sigma m_j$$即$(m_1,Y_{(1)}),...(m_n,Y_{(n)})$ 在XY平面分布在一条直线上
## 3.2 平稳过程的预测
最小二乘法线性预测：对$X_{n+h}$的估计量为$P_nX_{n+h}=a_0+a_1X_n+...+a_nX_1$ （拉格朗日）使其偏导为零解得$$\begin{align}a_0&=\mu(1-\sum_{i=1}^na_i)\\\Gamma_n\vec{a}_n&=\vec{\gamma}_n(h)\end{align}$$
	==**本质**==：在向量$1, X_1, X_2, ...,X_n$构成的线性空间中，找到距离$X_{n+h}$最短的点。所以如果$X_i$线性相关$\iff$$\vec{a}$解不唯一$\iff$$\Gamma_n$不可逆(不满秩)
**定理6**. 如果某平稳过程自协方差函数满足$\gamma(0)>0且\lim_{h\to \infty}\gamma(h)=0$则对于所有n，矩阵$\Gamma_n$可逆
$\vec{W}=\{W_n,...,W_1\}$作为参数，Y作为自变量，定义**预测算子**$P(·|\vec{W})$，满足如下性质：$$\begin{align}P(Y|\vec{W})&=\mu_Y+\vec{a}·(\vec{W}-\vec{\mu}_W).\\E[(Y-P(Y|\vec{W}))^2]&=Var(Y)-\vec{a}·\vec{\gamma}.\\E[U-P(Y|\vec{W})]&=0且E[U-P(Y|\vec{W})\vec{W}_i]=0.\\P(\alpha_1U+\alpha_2V+\beta|\vec{W})&=\alpha_1P(U|vec{W})+\alpha_1P(V|vec{W})+\beta.\\P(\sum_{i=1}^n\alpha W_i+\beta|\vec{W})&=\sum_{i=1}^n W_i+\beta.\\Cov(U,\vec{V})=0,则P(U|\vec{W})&=EU.\\令\vec{V}=(W_n,W_{n-1},...,W_{n-m+1})',则P(U|\vec{W})&=P(P(U|\vec{W}|\vec{V}).\end{align}$$
但n很大时，按定义求解很困难
### 3.2.1 Durbin-Levinson算法
递推求h=1
**定义7. 偏自相关函数（PAVF）** $$\alpha(h)=\begin{cases} 1,&h=0,\\\Gamma_h^{-1}\vec{\gamma}(h),&h>0.\end{cases}=Corr(X_{h+1}-P(X_{h+1}|X_2,...,X_h),X_1-P(X_1|X_2,...,X_h)).$$是$X_1$与$X_{h+1}$在排除了$X_2,...,X_h$影响之后的相关性
	与AVF具有对偶性，是AR(p)过程的$\rho(h)$，方差渐进正态，依旧可以用1.96做0.05的显著性检验。
### 3.2.2 新息（innovations）算法
	对于0均值随机变量
**定理 7**. 定义**新息** $U_n=X_n-\hat{X}_n$ 可由$\{1,...,X_n\}$ 线性组合 即 $\vec{X}_n=C_n(下三角)\vec{U}_n$ ，令$\vec{\hat{X}}_n=(0,P_1X_2,...,P_{n-1}X_n)'$ 可得$\vec{\hat{X}}_n=\vec X_n-\vec U_n=(C_n-I_n)\vec U_n=\Theta_n(\vec X_n-\vec{\hat{X}}_n)$，其中$\Theta_n=\left\{\begin{matrix}0&0&0&...&0\\\theta_{1,1}&0&0&...&0\\\theta_{2,2}&\theta_{2,1}&0&...&0\\\vdots&\vdots&\vdots&\ddots&0\\\theta_{n-1,n-1}&\theta_{n-1,n-2}&\theta_{n-1,n-3}&\cdots&0\end{matrix}\right\}$ 得$$\hat{X}_{n+1}=\sum_{j=1}^n\theta_{n,j}(X_{n+1-j}-\hat X_{n+1-j})$$
### 3.2.3 多步预测
$$P_n(X_{n+k}-P_{n+k-1}X_{n+k})=0$$
==**意义**==：在希尔伯特空间，向量$X_{n+k}$在子空间$A=Span(1,X_1,...,X_n)$的投影，等于它现在子空间$B=Span(1,X_1,...,X_n,...,X_{n+k-1})$上的投影，再投影到A上。于是：$$P_nX_{n+h}=\sum_{j=h}^{n+h-1}\theta_{n+h-1,j}(X_{n+h-j}-\hat X_{n+h-j})$$
预测的平均误差为：$E[(X_{n+h}-P_nX_{n+h})^2]=\kappa(n+h,n+h)-\sum_{j=h}^{n+h-1}\theta_{n+h-1,j}^2v_{n+h-j-1}.$
### 3.2.4 无穷多历史数据
定义极限$\tilde{P}_nX_{n+h}=\lim_{m\to -\infty}P_{m,n}X_{n+h}$ 与$P_n$性质类似
考虑因果可逆ARMA：$X_t-\phi X_{t-1}=Z_t+\theta Z_{t-1}, \{Z_t\}\sim WN(0,\sigma^2)$ 
### 3.2.5 Wold分解
**定义8. **确定过程**（diterministic）$\tilde{P}_nX_{n+1}={P}_nX_{n+1}$
定理9. 令$\{X_t\}_{t=-\infty}^\infty$ 为平稳过程且不是确定过程，则存在分解$$X_t=\sum_{j=0}^\infty \psi_jZ_{t-j}+V_t,\ Z\sim WN(0,\sigma^2)$$
其中$Z_t=X_t-\tilde{P}_{t-1}X_t,\ \psi_j=E[X_tZ_{t-}]/Z[Z_t^2],\ V_t=X_t-\sum_{j=0}^\infty \psi_jZ_{n-j}$，使得$\psi_0=1$且$\sum_{j=0}^\infty \psi_j^2 <\infty$，并且
	1. $\forall s,t \in \mathbb{Z},Cov(Z_s,V_t)=0$
	2. $\forall t,Z_t=\tilde{P}_tZ_t$ 
	3. $\forall t,s,V_t=\tilde{P}_sV_t$
	4. $\{V_t\}$是确定过程
# Chapter 4 ARMA(p,q)过程
## 4.1 ARMA
**定义9. AR(p)过程**(autoregression)：$X_t-\phi_1X_{t-1}-...-\phi_pX_{t-p}=Z_t \iff X_t=\frac1{\phi(B)}Z_t$  
	例如对于AR(1)：$X_t=Z_t+\phi X_{t-1}=\sum_{j=0}^\infty \phi^jZ_{t-j}$ 
	$|\phi|<1$时收敛，是因果的(causal)；
	$|\phi|>1$时是依赖于未来收敛的；
	$|\phi|=1$，不存在满足定义的平稳过程
**定义10. ARMA(p,q)过程**：$\phi(B)X_t=\theta(B)Z_t,\ \ \{Z_t\}\in WN(0,\sigma^2)$ 且没有公因子（自回归多项式&移动平均多项式）。一般的，其期望为0。
	**存在性：**$\phi(z)$ 在单位圆上没有零点
		==*证明*==：洛朗级数退化为泰勒
	**因果性**（causal）：$\phi(z)$ 在闭单位圆内没有零点，能写成Z的和
	**可逆性**（MA对应到AR的因果性，intertible）：$\theta(z)$ 在闭单位圆内都没有零点，能写成X的和
	注：二次求根$x= \displaystyle\frac { -b\pm \sqrt{\Delta }}{2a},\quad \Delta=b^2-4ac$ 
假设是因果的，即$X_t=\sum_{j=0}^\infty\psi_jZ_{t-j}$ 则$\gamma(h)=\sigma^2\sum_{j=0}^\infty\psi_j\psi_{j+|h|}$ 
## 4.2 ARMA过程的预测
对于$W_t=\begin{cases}\sigma^{-1}X_t,&t=1,...,max(p,q),\\\sigma^{-1}\phi(B)X_t=\sigma^{-1}\theta(B)X_t,&t>max(p,q).\end{cases}$ 利用新息算法（$W_t$与$X_t$线性空间相同）得到：$$\hat{X}_{n+1}=\begin{cases}\sum_{j=1}^n\theta_{n,j}(X_{n+1-j}-\hat{X}_{n+1-j})&,1\leqslant n<max(p,q)\\\phi_1X_n+...+\phi_pX_{n+1-p}+\sum_{j=1}^n\theta_{n,j}(X_{n+1-j}-\hat{X}_{n+1-j})&,n\geqslant max(p,q)\end{cases}$$且$$E(X_{n+1}-\hat X_{n+1})^2=\sigma^2E(W_{n+1}-\hat W_{n+1})^2=\sigma^2r_n$$
# Chapter 5 ARMA拟合
## 5.1 Yule-Walker估计
由**因果的**$\phi(B)X_t=Z_t$，对所有$p=0,1,...,p$，左右两边同乘$X_{t-k}$求期望得到：$$\left(\begin{matrix}\gamma(0)-\phi_1\gamma(1)-...-\phi_p\gamma(p)\\\gamma(-1)-\phi_1\gamma(0)-...-\phi_p\gamma(p-1)\\\vdots\\\gamma(-p)-\phi_1\gamma(1-p)-...-\phi_p\gamma(0)\end{matrix}\right)=\left(\begin{matrix}E[X_tZ_t]\\E[X_{t-1}Z_t]\\\vdots\\E[X_{t-p}Z_t]\end{matrix}\right)=\left(\begin{matrix}\sigma^2\\0\\\vdots\\0\end{matrix}\right)$$即得到估计量$$\hat{\Gamma}_p\hat{\vec{\phi}}=\hat{\vec{\gamma}}_p,\ \ \sigma^2=\gamma(0)-\vec{\phi}\cdot\vec{\gamma}(p).$$满足（**定理8**）：
1. $n^{1/2}(\hat{\vec{\phi}}-\vec{\phi})$依分布收敛到$N(0,\sigma^2\Gamma_p^{-1})$。
2. $\hat{\sigma}^2$依分布（等价于依概率）收敛到$\sigma^2$。
找到最好的阶：
1. 令q为最大使$|\hat{\alpha}(h)|>1.96n^{-1/2}$的h值。
2. 最小化**AICC统计量**(Akaike Information Criterion with correction)的那个阶。	$$AICC(p,q)=-2lnL(\vec{\hat{\phi}},\vec{\hat{\theta}},\hat{\sigma}^2)+2\frac{n(p+q+1)}{n-p-q-2}$$后半部分（第二个C）是对过高阶的惩罚项
## 5.2 Burg算法
先估计PACF，然后用估计的结果计算$\hat{\phi}$
`原理听不懂，算了叭`
## 5.3 新息算法
$MA(q): X_t=Z_t+\theta_1Z_{t-1}+...+\theta_qZ_{t-q}$
1. $Z_t=X_t-\tilde{P}_{t-1}X_t$ 是$X_t$相对于无穷历史的”新息“
2. $\begin{align}\tilde{P}_{t-1}X_t&=\theta_1Z_{t-1}+...+\theta_qZ_{t-q}\\&=\theta_1(X_{t-1}-P_{t-2}X_{t-1}+...+\theta_q(X_{t-q}-P_{t-q-1}X_{t-q})\\&=\sum_{j=1}^{t-1}\theta_{t-1,j}(X_{t-j}-P_{t-j-1}X_{t-j}).\end{align}$ 
设m很大，解出$MA(m)$的$\hat{\vec{\psi}}$后解出对应$\hat{\vec{\phi}}$和$\hat{\vec{\theta}}$ 
$$\left(\begin{matrix}\hat{\theta}_{m,q+1}\\\hat{\theta}_{m,q+2}\\\vdots\\\hat{\theta}_{m,q+p}\end{matrix}\right)=\left(\begin{matrix}\hat{\theta}_{m,q},&\hat{\theta}_{m,q-1},&\cdots&\hat{\theta}_{m,q+1-p}\\\hat{\theta}_{m,q+2},&\hat{\theta}_{m,q+1},&\cdots&\hat{\theta}_{m,q+2-p}\\\vdots&\vdots&\ddots&\vdots\\\hat{\theta}_{m,q+p-1},&\hat{\theta}_{m,q+p},&\cdots&\hat{\theta}_{m,q}\end{matrix}\right)\left(\begin{matrix}\phi_1\\\phi_2\\\vdots\\\phi_p\end{matrix}\right)$$$$\hat{\theta}_j=\hat{\theta}_{m,j}-\sum_{i=1}^{min(j,p)}\hat{\phi}_i\hat \theta_{j-i}$$
## 5.4 Hannan-Rissanen算法
可以估计ARMA
`原理听不懂，也算了叭`
## 5.5 极大似然估计
似然函数$$L(\sigma^2)=\frac1{\sqrt{2\pi\sigma^2}}exp(-\frac12x^2/\sigma^2)$$$$L(\Gamma_n)=\frac1{(2\pi)^{n/2}}(det\Gamma_n)^{-\frac12}exp(-\frac12\vec{x}'\Gamma_n^{-1}\vec{x}).$$
==*注*==：由于中心定理，所有分布经过运算后都近似正态分布。
## 5.6 对拟合的检验
残差检验：应该是白噪声
# Chapter 6 ARIMA(p,d,q)
## 6.1 非平稳过程
**定义11. (p,d,q)阶差分整合自回归滑动平均(AutoRegressive Integated Moving Average)过程**：随机过程$\{X_t\}$是ARIMA(p,d,q)过程，当且仅当对$\{X_t\}$做d次差分，得到$Y_t=(1-B)^dX_t$为因果的ARMA(p,q)过程，即$$\phi^*(B)X_t=\theta(B)Z_t,\ \{Z_t\}\sim WN(0,\sigma^2),\ \phi^*(z)=(1-z)^d\phi(z)$$
其ACF减小的非常慢，所以应该差分后拟合。如果强行用ARMA拟合，稳定性很差。
**Box-Cox变换**：取对数以减小方差变大的趋势
## 6.2 单位根检验
ARIMA过程比ARMA过程的$\phi(z)$多一个1的零点，所以可以检验$\phi=1$来判断ARIMA过程，即是否有(1-z)因子
	（ARMA中$\phi<1$不收敛无意义）
	**Dickey-Fuller检验**：检验差分的t-1项是否为0，令差分的方差最小，得到一个复杂的检验量符合一个特别复杂的分布。$$\hat\tau_\mu:=\frac{\hat\phi_1}{\hat{SE}(\hat\phi_1)}$$0.1、0.05、0.01置信区间分别为-3.43，-2.86，-2.57
如果差分次数过多，就会让$\theta(z)$带有(1-z)因子，通过检验$\theta(z)$改进估计
	判断$\lim_{n\to\infty}n(\hat\theta+1)$是否依分布收敛于$F(x)$，判断$\theta=-1$
## 6.3 ARIMA的预测
d=1时，令$Y_t=X_t-X_{t-1}$，则$X_t=X_0+\sum_{j=1}^tY_j.$ 
$$P_nX_{n+1}=X_n+P_nY_{n+1}$$
d>1时，由于$X_t=Y_t-\sum_{j=1}^d\left(\begin{matrix}d\\j\end{matrix}\right)(-1)^jX_{t-j}.$
$$P_nX_{n+h}=P_nY_{n+h}-\sum_{j=1}^d\left(\begin{matrix}d\\j\end{matrix}\right)(-1)^jX_{n+h-j}$$
## 6.4 Seasonal $ARIMA(p,d,q)×(P,D,Q)_s$
定义12. 令d和D为非负整数，随机过程$\{X_t\}$满足：$\{Y_t\}=(1-B)^d(1-B^s)^DX_t$是一个符合下列关系的因果的ARMA(p,q)过程。$$\phi(B)\Phi(B^s)Y_t=\theta(B)\Theta(B^s)Z_t,\ \ Z_t\sim WN(0,\sigma^2)$$其中$\phi(z)=1-\phi_1z-...\phi_pz^p, \Phi(z)=1-\Phi_1z-...\Phi_Pz^P, \theta(z)=1-\theta_1z-...\theta_qz^q, \Theta(z)=1-\Theta_1z-...\Theta_Qz^Q$ 
	d次差分掉d阶的趋势项
	D（非1可能没什么意义）次滞后s差分掉季节项
	得到平稳时间序列

例如若$Y_t=(1+\theta_1B)(1+\Theta_1B^{s})Z_t$，其ACF只有在1，s，1+s处不为零
# Chapter 7 平稳过程的谱分析
## 7.1 谱密度(spectral density)与谱分布函数
$$f(\lambda)=\frac1{2\pi}\sum^\infty_{h=-\infty}e^{-ih\lambda}\gamma(h).$$满足 **ACVF谱密度的性质**：
1. 偶函数
2. $2\pi$周期性，对于所有$\lambda \in(-\pi,pi],f(\lambda)\geqslant0$
3. $\gamma(h)=\int_{-\pi}^\pi e^{ih\lambda}f(\lambda)d\lambda$ (Wiener-Khinchin Theorem)
4. $\gamma(h)$其实就是$f(\lambda)$的傅里叶展开系数
$$\gamma(h)=\int_{(-\pi,\pi]}e^{ih\nu}dF(\nu)$$其中$F(\cdot)$是一个定义在$[-\pi,\pi]]$上的右连续、有界的非减函数，且满足$F(-\pi)=0$
**定理8：** 如果在自然数上定义的实数值函数$\gamma(h)$满足$\sum_{h=-\infty}^\infty|\gamma(h)|<\infty$，则它是某平稳过程的自相关函数，当且仅当满足：
1. 偶函数
2. $\forall\lambda\in(-\pi\,\pi],\ f(\lambda)=\frac1{2\pi}\sum^\infty_{h=-\infty}e^{-ih\lambda}\gamma(h)\geqslant0$
## 7.2 周期图估计
**定义12. 周期图**：对n个数据$\{x_1,...,x_n\}$$$I_n(\lambda)=\frac1n|\sum_{t=1}^nx_te^{-it\lambda}|^2.$$为标准正交基$\vec e_k=\frac1{\sqrt n}(e^{i\omega_k},e^{2i\omega_k},...,e^{ni\omega_k})',\ -(n-1)/2\leqslant k\leqslant n/2$ 的 $a_k=\vec e_k^*\vec x=\frac1{\sqrt n}\sum_{t=1}^nx_te^{-it\omega_k}$ 的平方差值
**定理9. 时间序列的样本自相关函数与其周期图函数关系**：$$I_n(\omega_k)=\sum_{|h|<n}\hat\gamma(h)e^{-ih\omega_k}$$
**定义13. 离散谱平均估计量**(discrete spectral average estimator)：$$\hat f(\lambda)=\frac1{2\pi}\sum_{|j|<m_n}W_n(j)I_n(g(n,\lambda)+n^{-1}2\pi j)$$
	其中$m_n$满足$\lim_{n\to\infty}m_n=+\infty,\ \ \lim_{n\to\infty}\frac{m_n}n=0$，
	权函数$W_n(j)$满足$W_n(j)\geqslant0,\ W_n(-j)=W_n(j),\ \sum_{|j|\leqslant m_n}W_n(j)=1,\ \sum_{|j|\leqslant m_n}W_n^2(j)=0.$
## 7.3 非时变线性滤波器(Time-invariant linear filters)
1. 线性$$Y_t=\sum_{k=-\infty}^\infty c_{t,k}X_k$$
2. 非时变$$c_{t,t-k}=\psi_k$$
3. 因果$$if\ j<0,\ \ \psi_j=0$$
故*指数平滑*和*移动平均滤波*都是非时变线性滤波器，但前者是因果的，而后者不是
**定理10**. 令$\{X_t\}$为零期望平稳过程，令$\sum_{k=-\infty}^\infty|\psi_k|<\infty$，则由$Y_t=\sum_{j=-\infty}^\infty\psi_jX_{t-j}$定义的平稳过程$\{Y_t\}$满足$$f_Y(\lambda)=|\Psi(e^{-i\lambda})|^2f_X(\lambda)=\Psi(e^{-i\lambda})\Psi(e^{i\lambda})f_X(\lambda)$$其中$f_X(\lambda)$$f_Y(\lambda)$分别是各自谱密度，而$\Psi(z)=\sum_{j=-\infty}^\infty\psi_jz^j$。
## 7.4 ARMA(p,q)过程的谱密度
$$f_X(\lambda)=\frac{\sigma^2}{2\pi}\frac{|\theta(e^{-i\lambda})|^2}{|\phi(e^{-i\lambda})|^2},\ \ -\pi<\lambda\leqslant\pi.$$
对于ARMA(1,1):$$f_X(\lambda)=\frac{\sigma^2(1+\theta^2+2\theta\cos\lambda)}{2\pi(1+\phi^2-2\phi\cos\lambda)}$$
# Chapter 8 多元时间序列
## 8.1 基本性质
考虑平稳二元随机过程$X_t=(X_{t,1},X_{t,2})'$，每个$X_t$有期望$$\mu_t=\left(\begin{matrix}EX_{t,1}\\EX_{t,2}\end{matrix}\right)$$
自协方差函数（相互先后影响）$$\Gamma(h)=\left(\begin{matrix}\gamma_{11}(h)&\gamma_{12}(h)\\\gamma_{21}(h)&\gamma_{22}(h)\end{matrix}\right)=\left(\begin{matrix}Cov(X_{t+h,1},X_{t,1})&Cov(X_{t+h,1},X_{t,2})\\Cov(X_{t+h,2},X_{t,1})&Cov(X_{t+h,2},X_{t,2})\end{matrix}\right)$$
自相关函数$$R(h)=(\rho_{i,j}(h))^n_{i,j=1},\ \ \rho_{i,j}(h)=\frac{\gamma_{i,j}(h)}{\sqrt{\gamma_{i,i}(0)\gamma_{j,j}(0)}}$$
样本自协方差矩阵函数$$\hat\Gamma(h)=(\hat\gamma_{i,j}(h))^n_{i,j=1}=\begin{cases}\frac1n\sum_{t=1}^{n-h}(x_{t+h}-\bar x_n)(x_{t+h}-\bar x_n)',&0\leqslant h\leqslant n-1\\\hat\Gamma(-h),&1-n\leqslant h\leqslant 0\end{cases}$$
**定理11**. 对于一个m元平稳过程的自协方差函数$\Gamma(\cdot)$满足：
1. $\Gamma(h)=\Gamma(-h)'$
2. $|gamma_{i,j}(h)|\leqslant\sqrt{\gamma_{i,i}(0)\gamma_{j,j}(0)}$
3. $\forall\vec a_1,...,\vec a_n\in \mathbb{R}^m,\ \ \sum_{i,j=1}^n\vec a_i'\Gamma(i-j)\vec a_j\geqslant 0$
**定理12. Bartlett公式**: 令$\{X_t=(X_{t,1},X_{t,2})'\}$为零期望的二元平稳过程，其任意有限多个$X_{t_1,i_1},...,X_{t_k,i_k}$的联合分布是正态分布，切齐正相关函数满足$\sum_{h=-\infty}^\infty|\gamma_{i,j}(h)|<\infty,\ \ i,j=1,2$，则：$$\begin{aligned}\lim_{n\to\infty}&\text{Cov}\left(\sqrt{n}(\hat{\rho}_{1,2}(h)-\rho_{1,2}(h)),\sqrt{n}(\hat{\rho}_{1,2}(k)-\rho_{1,2}(k))\right)\\=\sum_{j=-\infty}^{\infty}&[\rho_{11}(j)\rho_{22}(j+k-h)+\rho_{12}(j+k)\rho_{21}(j-h)\\& -\rho_{12}(h)\{\rho_{11}(j)\rho_{12}(j+k)+\rho_{22}(j)\rho_{21}(j-k)\}\\&-\rho_{12}(k)\{\rho_{11}(j)\rho_{12}(j+h)+\rho_{22}(j)\rho_{21}(j-h)\}\\& +\rho_{12}(h)\rho_{12}(k)\{\frac{1}{2}\rho_{1,1}^2(j)+\rho_{1,2}^2(j)+\frac{1}{2}\rho_{2,2}^2(j)\}].\end{aligned}$$
**定义14.** 0期望，自协方差矩阵为$\Sigma$的白噪声$\{Z_t\}\sim WN(0,\Sigma)$，独立同分布则为IID
**定理13.** 令$\{X_t=(X_{t,1},X_{t,2})'\}$为二元平稳过程，且$$\begin{aligned}X_{t,1}=\sum_{k=-\infty}^\infty \alpha_kZ_{t-k,1},\ \ \ \{Z_{t,1}\}\sim IDD(0,\sigma_1^2)\\X_{t,2}=\sum_{k=-\infty}^\infty \beta_kZ_{t-k,2},\ \ \ \{Z_{t,2}\}\sim IDD(0,\sigma_2^2)\end{aligned}$$且$\alpha_k,\ \beta_k$级数绝对收敛，于是当$n\to\infty$时，如果$h\ne k$，则：
1. $\sqrt n(\hat{\rho}_{12}(h),\hat{\rho}_{12}(k))'$依概率收敛到一个零期望的二元正态分布
2. $\begin{aligned}\mathrm{Var}(\sqrt{n}\hat{\rho}_{12}(h))&=\sum_{j=-\infty}^{\infty}\rho_{11}(j)\rho_{22}(j),\\\mathrm{Cov}(\sqrt{n}\hat{\rho}_{12}(h),\sqrt{n}\hat{\rho}_{12}(k))&=\sum_{j=-\infty}^{\infty}\rho_{11}(j)\rho_{22}(j+k-h)\end{aligned}$ 
![Pasted image 20240515111310.png](/img/user/Pasted%20image%2020240515111310.png)纽约股市可以在第二天影响悉尼
## 8.2 预测
Durbin-Levinson算法类似
## 8.3 多元ARMA(p,q)过程
**定义15. 以$\mu$为期望的m元ARMA过程**：$\{X_t-\mu\}$满足$$\mathbf{X}_t-\Phi_1\mathbf{X}_{t-1}-\cdots-\Phi_p\mathbf{X}_{t-p}=\mathbf{Z}_t+\Theta_1\mathbf{Z}_{t-1}+\cdots+\Theta_q\mathbf{Z}_{t-q},\quad\{\mathbf{Z}_t\}\sim\mathrm{WN}(0,\Sigma),$$
	因果性：对于$|z|\leq1\land z\in\mathbb{C},\ \det\Phi(z)=\det(I-\Phi_1z-\cdots-\Phi_pz^p)\neq0.$即$\Phi$的特征值的绝对值都小于1。这样的话即可满足$\mathbf{X}_t=\sum_{j=0}^\infty\Psi_j\mathbf{Z}_{t-j}$，其中$\Psi_j=\Theta_j+\sum_{k=1}^\infty\Phi_k\Psi_{j-k}.$$(\text{令}\Theta_0=I,\text{对}j>q\text{令}\Theta_j=0,\text{对}j>q\text{令 }\Phi_j=0,\text{对}j<0令\Psi_j=0)$ 
	可逆性：对于$|z|\leq1\land z\in\mathbb{C},\ \det\Theta(z)=\det(I-\Theta_1z-\cdots-\Theta_qz^q)\neq0.$即$\Theta$的特征值的绝对值都小于1。 这样的话即可满足$\mathbf{Z}_t=\sum_{j=0}^\infty\Pi_j\mathbf{X}_{t-j}$ 其中$\Pi_j=-\Phi_j-\sum_{k=1}^\infty\Theta_k\Pi_{j-k}.$ (令$\Phi_0=-I$,对$j>q$令$\Theta_j=0$,对$j>q$令$\Phi_j=0$,对$j<0$令$\Pi_j=0)$
## 8.4 拟合
似然函数$$L(\vec{\Phi},\Sigma)=(2\pi)^{-nm/2}\left(\prod_{j=1}^n\det V_{j-1}\right)^{-1/2}\exp\left(-\frac12\sum_{j=1}^n\mathbf{U}_j^{\prime}V_{j-1}^{-1}\mathbf{U}_j\right)$$
## 8.5 共整合性 Cointegration
**定义16. d阶整合(integrated of order d)**：对于一个非平稳过程$\{X_t\}$,如果求过$d$阶差分之后的的结果$\{\nabla^dX_t\}$平稳而$\{\nabla^{d-1}X_t\}$不平稳。例如$$X_t=\sum_{j=1}^tZ_j,\quad Y_t=X_t+W_t,\quad\{Z_t\}\sim\text{IID}(0,\sigma^2),\quad\{W_t\}\sim\text{IID}(0,\tau^2).\quad\alpha=(1,-1)'.$$
**定义17. 共整合(Cointegration)**：存在一个共整合向量$\alpha$使得$\{\alpha' X_t\}$的整合阶数小于d。
# Chapter 10 GARCH(p,q)
*金融领域*中，定义收益为$$Z_t=X_t-X_{t-1},\quad X_t=\log(股票价格P_t)$$满足典型化事实(stylized facts)：
1. 每个时间的随机变量分布是重尾的(heavy tail)。
2. 波动性(volatility)持续(persistence)：$Z_t$的波动较大，$Z_{t+1}$波动多半较大。
3. 聚集高斯性(aggregational Gaussianity)：$lim_{n\to\infty}\sum_{t=1}^nZ_t$为正态分布。
4. 正负波动不对称。
5. 波动常常存在长时间相关性。
GARCH模型满足前三条，想要满足全部可以推广为IGARCH、EGARCH、FIGARCH
**定义17. ARCH模型(AutoRegressive Conditional Heterocedasticity)**：$Z_t$由前向白噪声决定$$Z_t=\sqrt{h_t}e_t,\quad\{e_t\}\sim\text{IID N}(0,1),\quad h_t=\alpha_0+\sum_{i=1}^p\alpha_iZ_{t-i}^2.$$例如ARCH(1)：$$\begin{aligned}
Z_{t}^{2}& =\alpha_0e_t^2+\alpha_1Z_{t-1}^2e_t^2  \\
&=\alpha_0e_t^2+\alpha_1\alpha_0e_t^2e_{t-1}^2+\alpha^2e_t^2e_{t-1}^2 \\
&=\ldots  \\
&=\underbrace{\alpha_0\sum_{j=0}^\infty\alpha_1^je_t^2e_{t-1}^2\cdots e_{t-j}^2}_{\text{如果 }\alpha_1<1,\text{ 则当 }n\to\infty\text{ 时收敛}}+\underbrace{\alpha_1^{n+1}Z_{t-n-1}^2e_t^2e_{t-1}^2\cdots e_{t-n}^2}_{\text{如果 }\alpha_1<1,\text{ 则当 }n\to\infty\text{ 时趋近 }0}.
\end{aligned}$$为严平稳过程且$\gamma_{h>0}=0$，但它不是IID白噪声，具有重尾性
**GARCH**：$$Z_t=\sqrt{h_t}e_t,\quad\{e_t\}\sim\text{ IID N}(0,1),\quad h_t=\alpha_0+\sum_{i=1}^p\alpha_iZ_{t-i}^2+\sum_{j=1}^q‘b_jh_{t-j}$$
# 附：期末
## a. ARMA的定阶
ACF拖尾，**PACF**截尾：**AR**
**ACF**截尾，PACF拖尾：**MA**
## b. 可逆性与因果性的判定
$$X_t+...+\phi_pX_{t-p}=Zt+...+\theta_qZ_{t-q}$$
因果性$\Phi(z)$，可逆性$\theta(z)$，但闭单位圆内没有零点
## c. 谱分析
$\gamma(h)=\int_{-\pi}^\pi e^{ih\lambda}f(\lambda)d\lambda.$ 是谱密度的傅里叶展开系数
$f(\lambda)=\frac1{2\pi}\sum^\infty_{h=-\infty}e^{-ih\lambda}\gamma(h).$ 是自相关函数的傅里叶变换
有关欧拉定理：
	$e^{ix}=\cos x+i\sin x$
	$e^{ix}+e^{-ix}=2\cos x$
	$e^{ix}-e^{-ix}=2i\sin x$
## d. 新息算法
$$\hat{X}_{n+1}=\sum_{j=1}^n\theta_{n,j}(X_{n+1-j}-\hat X_{n+1-j})$$
其中$$\Theta_n=\left\{\begin{matrix}0&0&0&...&0\\\theta_{1,1}&0&0&...&0\\\theta_{2,2}&\theta_{2,1}&0&...&0\\\vdots&\vdots&\vdots&\ddots&0\\\theta_{n-1,n-1}&\theta_{n-1,n-2}&\theta_{n-1,n-3}&\cdots&0\end{matrix}\right\}$$且$n\to\infty$时，$\theta_{n,1}、\phi_{n,1}=\theta、\phi$ 
$P_nX_{n+1}=\phi P_nX_n+\theta(X_n-\hat X_n)$ 
$\tilde{P}_nX_{n+h}=\sum_{j=h}^\infty\psi_jZ_{n+h-j},$
$\operatorname{E}(X_{n+h}-\tilde{P}_{n}X_{n+h})^{2}=\sigma^2\sum_{j=0}^{h-1}\psi_{j}^{2}。$
## e. $\psi$的妙用
$$\psi(z)=\theta(z)/\phi(z)$$或者迭代去求
1. 信息算法预测的误差$\sigma^2\sum_{j=0}^{h-1}\psi_{j}^{2}$
2. 非时变线性滤波器$f_Y(\lambda)=\Psi(e^{-i\lambda})\Psi(e^{i\lambda})f_X(\lambda)$ 
## f. 极大似然估计
$${\Large f(x)=\frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}} \quad(\mu \in R, \sigma>0)}$$